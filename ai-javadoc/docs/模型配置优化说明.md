# 模型配置优化说明

## 📋 优化概览

已将模型选择从**固定列表**优化为**可自由输入**，提供了更灵活的模型配置方式。

---

## 🎯 优化内容

### 1. UI 变更

**之前：**

- 模型选择框是不可编辑的下拉列表
- 用户只能从预定义的模型中选择

**现在：**

- ✅ 模型选择框改为**可编辑的下拉框**
- ✅ 用户可以**自由输入任何模型名称**
- ✅ 同时保留**推荐模型列表**作为参考
- ✅ 添加提示文字："提示: 可输入任何模型"

### 2. 代码变更

#### JavaDocSettingsPanel.java

```java
// 创建可编辑的模型下拉框
modelComboBox = new ComboBox<>();
modelComboBox.setEditable(true);  // ✅ 允许用户输入自定义模型名称

// 获取用户输入的模型名称（可能是从列表选择的，也可能是手动输入的）
Object selectedModel = modelComboBox.getEditor().getItem();
settings.modelName = selectedModel != null ? selectedModel.toString().trim() : "";
```

#### OllamaProvider.java

```java
/**
 * 推荐的常用模型列表（仅作为参考）
 * 用户可以使用任何通过 ollama pull 下载的模型
 */
private static final List<String> SUGGESTED_MODELS = Arrays.asList(
    // 通义千问系列（推荐用于中文）
    "qwen:7b",
    "qwen:14b",
    
    // 代码专用模型（推荐用于代码文档生成）
    "codellama:7b",
    "deepseek-coder:6.7b",
    
    // 通用模型
    "llama2:7b",
    "mistral:7b"
);

/**
 * 返回推荐的模型列表
 * 
 * <p>注意：这只是推荐列表，用户可以使用任何已安装的 Ollama 模型。
 * 可以通过 `ollama list` 命令查看本地已安装的模型。
 * 
 * @return 推荐的模型列表（作为参考）
 */
@NotNull
@Override
public List<String> getSupportedModels() {
    return SUGGESTED_MODELS;
}
```

#### QianWenProvider.java

```java
/**
 * 常用模型列表（仅作为参考）
 * 通义千问支持更多模型，用户可以根据需要使用官方文档中的任何模型
 */
private static final List<String> SUGGESTED_MODELS = Arrays.asList(
    "qwen-max",          // 最新最强大的模型（推荐）
    "qwen-plus",         // 性价比较高
    "qwen-turbo"         // 速度最快
);

/**
 * 返回常用模型列表
 * 
 * <p>注意：这只是常用模型列表，用户可以使用通义千问支持的任何模型。
 * 请参考官方文档获取完整的模型列表。
 * 
 * @return 常用模型列表（作为参考）
 */
@NotNull
@Override
public List<String> getSupportedModels() {
    return SUGGESTED_MODELS;
}
```

---

## 💡 使用场景

### Ollama 用户

**查看已安装的模型：**

```bash
ollama list
```

**输出示例：**

```
NAME                      ID              SIZE      MODIFIED
qwen:7b                   6b8e0...        4.7 GB    2 days ago
deepseek-coder:6.7b       3f8a1...        3.8 GB    1 week ago
codellama:13b             5d91c...        7.3 GB    3 weeks ago
```

**在插件设置中：**

1. AI 提供商：选择 `ollama`
2. 模型：可以输入 `qwen:7b`、`deepseek-coder:6.7b`、`codellama:13b` 或任何其他已安装的模型

### 通义千问用户

**官方支持的模型：**

- `qwen-max`（推荐）
- `qwen-plus`
- `qwen-turbo`
- `qwen-max-longcontext`
- `qwen-long`
- 以及更多新发布的模型...

**在插件设置中：**

1. AI 提供商：选择 `qianwen`
2. 模型：可以从列表选择，也可以输入官方文档中的任何模型名称

---

## 🎨 UI 效果

```
┌─────────────────────────────────────────────────┐
│ 模型:  [qwen:7b         ▼] 提示: 可输入任何模型 │
└─────────────────────────────────────────────────┘
         ↑                  ↑
    可编辑输入框         提示文字
```

**用户可以：**

- ✅ 点击下拉箭头，从推荐列表中选择
- ✅ 直接在输入框中输入任何模型名称
- ✅ 编辑已选择的模型名称

---

## 📝 注释优化

所有相关类都添加了详细的 JavaDoc 注释，说明：

### OllamaProvider

- 添加了"查看已安装模型"的命令说明
- 明确说明推荐模型"仅供参考"
- 精简了推荐模型列表（从 12 个减少到 6 个常用模型）

### QianWenProvider

- 添加了 DashScope 控制台链接
- 明确说明用户可以使用"任何官方支持的模型"
- 精简了推荐模型列表（从 5 个减少到 3 个常用模型）

### JavaDocSettingsPanel

- 更新了 `updateModelList()` 方法的逻辑
- 保存和恢复用户输入的模型名称
- 添加了 `createModelPanel()` 方法创建带提示的面板

---

## ✅ 优势

### 1. **灵活性**

- 用户不受限于预定义的模型列表
- 可以使用任何新发布的模型，无需更新插件

### 2. **便利性**

- Ollama 用户可以使用任何本地安装的模型
- 通义千问用户可以使用官方文档中的所有模型

### 3. **向后兼容**

- 推荐模型列表仍然存在，方便新用户选择
- 不影响现有用户的配置

### 4. **扩展性**

- 将来添加新的 AI 提供商时，只需提供推荐列表
- 用户始终可以输入自定义模型名称

---

## 🔄 迁移指南

**现有用户：**

- ✅ 无需任何操作
- 已配置的模型会自动保留
- 新的输入方式完全向后兼容

**新用户：**

1. 选择 AI 提供商
2. 从推荐列表中选择模型，或直接输入模型名称
3. 配置其他参数（Base URL、API Key 等）
4. 保存设置

---

## 📚 参考资源

### Ollama

- 官网：https://ollama.ai
- 模型库：https://ollama.ai/library
- 查看本地模型：`ollama list`
- 拉取新模型：`ollama pull <model-name>`

### 通义千问

- 官方文档：https://help.aliyun.com/zh/dashscope/
- 控制台：https://dashscope.console.aliyun.com/
- API 文档：https://help.aliyun.com/zh/dashscope/developer-reference/api-details

---

## 🎯 测试建议

### 测试场景 1：使用推荐模型

1. 打开设置面板
2. 点击模型下拉框
3. 从列表中选择一个推荐模型
4. 保存并测试

### 测试场景 2：输入自定义模型

1. 打开设置面板
2. 在模型输入框中直接输入自定义模型名称
3. 例如：`deepseek-coder:33b` 或 `qwen-max-longcontext`
4. 保存并测试

### 测试场景 3：编辑已选择的模型

1. 打开设置面板
2. 点击模型输入框
3. 修改现有的模型名称
4. 保存并测试

